{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c5c5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d631a22",
   "metadata": {},
   "source": [
    "Getting latest model from models folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3637d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('Tensorflow','workspace','my_models')\n",
    "models_names = [name for name in os.listdir(model_path) if os.path.isdir(model_path)]\n",
    "models_names = [os.path.join(model_path,f) for f in models_names]\n",
    "print('MODELS BEFORE SORT: ',models_names)\n",
    "models_names.sort(key=lambda x: os.path.getmtime(x))\n",
    "print('MODELS AFTER SORT: ',models_names)\n",
    "\n",
    "latest_model_name = os.path.basename(os.path.normpath(models_names[len(models_names)-1]))\n",
    "print(\"MODEL: \",latest_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b70572",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = 'test' #images folder with adnotation files to detect\n",
    "CUSTOM_MODEL_NAME = latest_model_name\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b329d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','my_models',CUSTOM_MODEL_NAME,'dev','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','my_models',CUSTOM_MODEL_NAME) \n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','my_models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445d8faa",
   "metadata": {},
   "source": [
    "Getting latest checkpoint from models folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ddf26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names_in_model_dir = os.path.join('Tensorflow','workspace','my_models',CUSTOM_MODEL_NAME)\n",
    "ckpt_files = []\n",
    "all_files_from_model_dir = [f for f in listdir(file_names_in_model_dir) if isfile(join(file_names_in_model_dir, f))] #lista nazw plikow\n",
    "for i in all_files_from_model_dir :\n",
    "    if i[-1]=='x': (ckpt_files.append(i))\n",
    "print(ckpt_files)\n",
    "numbers = []\n",
    "temp_num = \"\"\n",
    "# extract number of ckpt files:\n",
    "for one_name in ckpt_files:\n",
    "    for c in one_name:\n",
    "        if c.isdigit(): # finding numbers in string\n",
    "            temp_num = temp_num + c\n",
    "    numbers.append(int(temp_num))\n",
    "    temp_num=\"\"\n",
    "    max_num = max(numbers)#largest number from list\n",
    "latest_checkpoint_name = \"ckpt-\"+str(max_num)  #name of latest checkpoint\n",
    "print(CUSTOM_MODEL_NAME,'---------->',latest_checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf5726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'],latest_checkpoint_name)).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458d555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ca987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TEST_PATH = os.path.join(paths['CHECKPOINT_PATH'],'dev','img',img_folder)\n",
    "RIGHT_DETECTION_FILE_NAME =[]\n",
    "BAD_DETECTION_FILE_NAME =[]\n",
    "detection_status=\"\"\n",
    "\n",
    "files = [f for f in listdir(TEST_PATH) if isfile(join(TEST_PATH, f))] #lista nazw plikow\n",
    "files.sort()\n",
    "jpg_images = [] #list for image names\n",
    "for i in files:\n",
    "    if i[-1]=='g':\n",
    "        jpg_images.append(i)\n",
    "\n",
    "\n",
    "for image_name in jpg_images:\n",
    "    IMAGE_PATH = os.path.join(TEST_PATH, image_name)\n",
    "    \n",
    "    img = cv2.imread(IMAGE_PATH)\n",
    "    image_np = np.array(img)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=1,\n",
    "                min_score_thresh=.1,\n",
    "                agnostic_mode=False)\n",
    "    \n",
    "    #-----checking if detection is legit\n",
    "#     image_name.rstrip('.jpg')\n",
    "    do_nazwy = category_index[detections['detection_classes'][0]+label_id_offset] #wydobycie danej sekcji z nazwa\n",
    "    finded_object_name = do_nazwy['name']\n",
    "\n",
    "    XML_PATH = os.path.join(paths['CHECKPOINT_PATH'],'dev','img',img_folder,image_name.rstrip('jpg')+\"xml\")\n",
    "    root = etree.parse(XML_PATH) #open xml file\n",
    "    myroot = root.getroot() \n",
    "    label_name_from_xml = (myroot.find('.//name')).text #getting name from xml file\n",
    "    if finded_object_name == label_name_from_xml:\n",
    "        RIGHT_DETECTION_FILE_NAME.append(image_name)\n",
    "        detection_status=\"YES\"\n",
    "    else:\n",
    "        BAD_DETECTION_FILE_NAME.append(image_name)\n",
    "        detection_status=\"NO\"\n",
    "    #-----checking if detection is legit\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(image_name,\"|\",\"class:\",detections['detection_classes'][0],\"| detection:\",detections['detection_scores'][0],\"|\",finded_object_name,\"|\",detection_status)\n",
    "    print(detections['detection_boxes'][0])\n",
    "    \n",
    "    plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "print(f\"Correctly detected: {len(RIGHT_DETECTION_FILE_NAME)}\")\n",
    "print(RIGHT_DETECTION_FILE_NAME)\n",
    "print(f\"Incorrectly detected: {len(BAD_DETECTION_FILE_NAME)}\")\n",
    "print(BAD_DETECTION_FILE_NAME)\n",
    "print(\"Performance: \",(len(RIGHT_DETECTION_FILE_NAME)/len(jpg_images))*100,\"%\" )\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0bb6ba",
   "metadata": {},
   "source": [
    "# Real Time Detections from Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7e14e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# while cap.isOpened(): \n",
    "#     ret, frame = cap.read()\n",
    "#     image_np = np.array(frame)\n",
    "    \n",
    "#     input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "#     detections = detect_fn(input_tensor)\n",
    "    \n",
    "#     num_detections = int(detections.pop('num_detections'))\n",
    "#     detections = {key: value[0, :num_detections].numpy()\n",
    "#                   for key, value in detections.items()}\n",
    "#     detections['num_detections'] = num_detections\n",
    "\n",
    "#     # detection_classes should be ints.\n",
    "#     detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "#     label_id_offset = 1\n",
    "#     image_np_with_detections = image_np.copy()\n",
    "\n",
    "#     viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "#                 image_np_with_detections,\n",
    "#                 detections['detection_boxes'],\n",
    "#                 detections['detection_classes']+label_id_offset,\n",
    "#                 detections['detection_scores'],\n",
    "#                 category_index,\n",
    "#                 use_normalized_coordinates=True,\n",
    "#                 max_boxes_to_draw=1,\n",
    "#                 min_score_thresh=.3,\n",
    "#                 agnostic_mode=False)\n",
    "\n",
    "#     cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (640, 480)))\n",
    "    \n",
    "#     if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#         cap.release()\n",
    "#         cv2.destroyAllWindows()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ff0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
